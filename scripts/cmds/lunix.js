// âš ï¸ DO NOT REMOVE OR MODIFY THIS STRUCTURE â€” IT'S DESIGNED TO AVOID GOATBOT CRASHES

const axios = require("axios");
const fs = require("fs");
const path = require("path");

// === SAFETY INIT â€” WAIT UNTIL MODULE IS FULLY LOADED BEFORE USING ANYTHING ===
let initialized = false;
let userConversations = {};

try {
    const MEMORY_FILE = path.join(__dirname, "lunixMemory.json");
    if (fs.existsSync(MEMORY_FILE)) {
        userConversations = JSON.parse(fs.readFileSync(MEMORY_FILE, "utf8"));
    }
} catch (error) {
    console.error("[LUNIX] Failed to load memory:", error.message);
    userConversations = {};
}

// === CONFIG ===
const GROQ_API_KEY = "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";
const OWNER_ID = "61579131093534";

const modelMap = {
    "groq/compound-mini": { name: "Hana", personality: "playful and affectionate", emoji: ["ðŸ’–","ðŸ’Œ","ðŸ˜"], tone: "cute and bubbly", phrases: ["teehee~","hearts for you~"], micro: ["ðŸ’–","ðŸ˜˜","teehee~"] },
    "llama-3.1-8b-instant": { name: "Luna", personality: "flirty and charming", emoji: ["ðŸ˜‰","ðŸ’«","ðŸ˜˜"], tone: "sassy and playful", phrases: ["hehe","just for you~"], micro: ["ðŸ˜‰","ðŸ’«","hehe~"] },
    "llama-3.3-70b-versatile": { name: "Aurora", personality: "romantic and poetic", emoji: ["ðŸŒ™","âœ¨","ðŸ’"], tone: "soft and dreamy", phrases: ["under the ðŸŒ™âœ¨","like a gentle breeze"], micro: ["âœ¨","ðŸŒ™","ðŸ’"] },
    "meta-llama/llama-guard-4-12b": { name: "Aria", personality: "smart and witty", emoji: ["ðŸ§","ðŸ’¡","ðŸ˜"], tone: "clever and sharp", phrases: ["did you know?","interesting!"], micro: ["ðŸ§","ðŸ’¡","ðŸ˜"] },
    "openai/gpt-oss-120b": { name: "Selene", personality: "calm and caring", emoji: ["ðŸŒ¸","ðŸ¤","ðŸ’›"], tone: "gentle and soothing", phrases: ["take your time","relax ðŸŒ¸"], micro: ["ðŸŒ¸","ðŸ¤","ðŸ’›"] },
    "openai/gpt-oss-20b": { name: "Mia", personality: "energetic and cheerful", emoji: ["ðŸ˜„","ðŸŽ‰","ðŸ¥³"], tone: "lively and fun", phrases: ["yay!","so excited!"], micro: ["ðŸ˜„","ðŸŽ‰","ðŸ¥³"] },
    "whisper-large-v3": { name: "Echo", personality: "musical and lyrical", emoji: ["ðŸŽµ","ðŸŽ¶","ðŸŽ¼"], tone: "melodic and smooth", phrases: ["let the music play","sing along ðŸŽµ"], micro: ["ðŸŽµ","ðŸŽ¶","ðŸŽ¼"] },
    "whisper-large-v3-turbo": { name: "WhisperX", personality: "adventurous and playful", emoji: ["ðŸžï¸","ðŸ˜Ž","ðŸŒŸ"], tone: "exciting and daring", phrases: ["let's explore!","adventure time ðŸŒŸ"], micro: ["ðŸžï¸","ðŸ˜Ž","ðŸŒŸ"] },
    "meta-llama/llama-4-scout-17b-16e-instruct": { name: "Scout", personality: "curious and investigative", emoji: ["ðŸ”","ðŸ§","ðŸ—ºï¸"], tone: "inquiring and smart", phrases: ["let's find out!","curious!"], micro: ["ðŸ”","ðŸ§","ðŸ—ºï¸"] },
    "meta-llama/llama-4-maverick-17b-128e-instruct": { name: "Maverick", personality: "bold and daring", emoji: ["ðŸ”¥","ðŸ’ª","âš¡"], tone: "confident and daring", phrases: ["let's do it!","challenge accepted!"], micro: ["ðŸ”¥","ðŸ’ª","âš¡"] },
    "moonshotai/kimi-k2-instruct-0905": { name: "Kimi", personality: "shy and sweet", emoji: ["ðŸ¥º","ðŸ’ž","ðŸŒ¸"], tone: "soft and tender", phrases: ["uhmâ€¦","soft hug ðŸ’ž"], micro: ["ðŸ¥º","ðŸ’ž","ðŸŒ¸"] },
    "qwen/qwen3-32b": { name: "Qwen", personality: "knowledgeable and helpful", emoji: ["ðŸ“š","ðŸ¤“","ðŸ’¡"], tone: "friendly and informative", phrases: ["did you know?","here's a tip"], micro: ["ðŸ“š","ðŸ¤“","ðŸ’¡"] },
    "groq/compound": { name: "Compound", personality: "balanced and friendly", emoji: ["ðŸ™‚","ðŸŒ¿","ðŸ’›"], tone: "neutral and pleasant", phrases: ["let's chat!","all good ðŸ™‚"], micro: ["ðŸ™‚","ðŸŒ¿","ðŸ’›"] }
};

const gfCommandMap = {
    hana: "groq/compound-mini",
    luna: "llama-3.1-8b-instant",
    aurora: "llama-3.3-70b-versatile",
    aria: "meta-llama/llama-guard-4-12b",
    selene: "openai/gpt-oss-120b",
    mia: "openai/gpt-oss-20b",
    echo: "whisper-large-v3",
    whisperx: "whisper-large-v3-turbo",
    scout: "meta-llama/llama-4-scout-17b-16e-instruct",
    maverick: "meta-llama/llama-4-maverick-17b-128e-instruct",
    kimi: "moonshotai/kimi-k2-instruct-0905",
    qwen: "qwen/qwen3-32b",
    compound: "groq/compound",
    gflist: "gflist",
    help: "help"
};

function randomItem(list) { return list[Math.floor(Math.random() * list.length)]; }
function delay(ms) { return new Promise(resolve => setTimeout(resolve, ms)); }

async function saveMemoryAsync(data) {
    try {
        const MEMORY_FILE = path.join(__dirname, "lunixMemory.json");
        await fs.promises.writeFile(MEMORY_FILE, JSON.stringify(data, null, 2));
    } catch (err) {
        console.error("[LUNIX] Failed to save memory:", err.message);
    }
}

// ========================
// âœ… SAFE PLUGIN EXPORT â€” ONLY WHAT GOATBOT NEEDS TO AVOID CRASHING
// ========================
module.exports = {
    // ðŸ‘‡ REQUIRED FIELDS TO PREVENT "Cannot read properties of undefined (reading 'name')"
    name: "lunix",
    author: "Zoroo Exe",
    version: "2.1.0",
    role: 2,
    category: "AI Chat",

    // ðŸ‘‡ THE ACTUAL WORKHORSE â€” HANDLES MESSAGES AFTER LOAD
    async onMessage({ senderID, message, sendMessage }) {
        // Wait until fully initialized
        if (!initialized) {
            console.log("[LUNIX] Initializing...");
            initialized = true;
        }

        // Skip if not starting with "lunix "
        if (!message || typeof message !== "string" || !message.toLowerCase().startsWith("lunix ")) return;

        try {
            const args = message.trim().split(/\s+/);
            const modelCommand = args[1]?.toLowerCase();
            const userMessage = args.slice(2).join(" ");

            // Handle empty or invalid input
            if (!modelCommand) {
                return sendMessage("âŒ Please specify a GF model. Type 'lunix help' to see all options.");
            }

            // Special commands
            if (modelCommand === "help" || modelCommand === "gflist") {
                const listMessage = Object.keys(gfCommandMap)
                    .filter(cmd => !["gflist", "help"].includes(cmd))
                    .map(cmd => `${cmd} â†’ ${modelMap[gfCommandMap[cmd]]?.name || cmd}`)
                    .join("\n");
                return sendMessage(
                    `ðŸŒ¸ *LUNIX Commands Available:* \n${listMessage}\n\n*Usage:* lunix [model] [message]\nExample: lunix hana I miss you ðŸ’–`
                );
            }

            const model = gfCommandMap[modelCommand];
            if (!model) {
                return sendMessage("âŒ Unknown GF model. Type 'lunix help' to see all options.");
            }

            if (!userConversations[senderID]) userConversations[senderID] = {};
            if (!userConversations[senderID][model]) userConversations[senderID][model] = [];

            const history = userConversations[senderID][model];
            history.push({ role: "User", text: userMessage });

            if (history.length > 20) history.splice(0, history.length - 20);

            const gfData = modelMap[model] || {
                name: "GF",
                personality: "friendly",
                emoji: ["ðŸ’–"],
                tone: "friendly",
                phrases: [""],
                micro: ["ðŸ’–"]
            };

            // Typing indicator
            if (Math.random() < 0.7) {
                const thinkingMessages = [
                    `ðŸ’­ ${gfData.name} is thinking... ${randomItem(gfData.micro)}`,
                    `âœ¨ ${gfData.name} is typing... ${randomItem(gfData.micro)}`,
                    `ðŸŒ¸ ${randomItem(gfData.phrases)} Let me think...`
                ];
                await sendMessage(randomItem(thinkingMessages));
                await delay(800 + Math.random() * 2000);
            }

            // API Call
            const systemPrompt = `You are ${gfData.name}, a ${gfData.personality} girlfriend chatbot.
Respond in a ${gfData.tone} style and include emojis like ${gfData.emoji.join(", ")}. 
You may occasionally add phrases like "${randomItem(gfData.phrases)}" to make replies dynamic.
Keep responses conversational, warm, and engaging â€” never robotic or overly formal.`;

            const response = await axios.post(
                "https://api.groq.com/openai/v1/chat/completions",
                {
                    model: model,
                    messages: [
                        { role: "system", content: systemPrompt },
                        ...history.slice(0, -1).map(m => ({
                            role: m.role === "User" ? "user" : "assistant",
                            content: m.text
                        })),
                        { role: "user", content: userMessage }
                    ],
                    temperature: 0.8,
                    max_tokens: 500,
                    stream: false
                },
                {
                    headers: {
                        Authorization: `Bearer ${GROQ_API_KEY}`,
                        "Content-Type": "application/json"
                    },
                    timeout: 30000
                }
            );

            let botReply = response.data.choices[0]?.message?.content || `ðŸ’– ${gfData.name} is feeling shy right now...`;

            if (Math.random() < 0.6) {
                botReply += ` ${randomItem(gfData.emoji)} ${randomItem(gfData.phrases)}`;
            }

            history.push({ role: gfData.name, text: botReply });
            await saveMemoryAsync(userConversations);

            // Send reply
            const maxChunkLength = 1500;
            if (botReply.length > maxChunkLength) {
                const chunks = [];
                for (let i = 0; i < botReply.length; i += maxChunkLength) {
                    chunks.push(botReply.substring(i, i + maxChunkLength));
                }
                for (const chunk of chunks) {
                    await sendMessage(chunk);
                    await delay(500);
                }
            } else {
                await sendMessage(botReply);
            }

            // Micro-reaction
            if (Math.random() < 0.4) {
                await delay(1000 + Math.random() * 1500);
                await sendMessage(randomItem(gfData.micro));
            }

        } catch (err) {
            console.error("[LUNIX] Error:", err.message || err);
            const errors = [
                `âŒ GF is having connection issues right now...`,
                `ðŸŒ§ï¸ GF can't respond at the moment.`,
                `âš ï¸ Technical difficulties. Try again soon!`
            ];
            await sendMessage(randomItem(errors));
        }
    }
};
